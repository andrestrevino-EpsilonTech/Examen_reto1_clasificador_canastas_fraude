{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificador de Fraude en Canastas de Compra\n",
    "\n",
    "Este notebook implementa un clasificador binario para detectar fraude en canastas de compra utilizando Regresi√≥n Log√≠stica.\n",
    "\n",
    "**Problema**: Predecir si una canasta de compra es fraudulenta bas√°ndose en los art√≠culos comprados y caracter√≠sticas agregadas.\n",
    "\n",
    "**Dataset**: 9,318 canastas con 2,474 productos + 6 caracter√≠sticas agregadas\n",
    "\n",
    "**Modelo principal**: Regresi√≥n Log√≠stica con regularizaci√≥n Ridge (similar al problema de detecci√≥n de spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Bibliotecas y Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    confusion_matrix, \n",
    "    classification_report,\n",
    "    roc_curve, \n",
    "    auc,\n",
    "    RocCurveDisplay\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuraci√≥n de visualizaci√≥n\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion_modelo(modelo, X_train, y_train, X_test, y_test, nombre_modelo='Modelo'):\n",
    "    \"\"\"\n",
    "    Eval√∫a el modelo en conjuntos de entrenamiento y prueba.\n",
    "    Muestra matrices de confusi√≥n lado a lado.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Evaluaci√≥n en entrenamiento\n",
    "    y_train_pred = modelo.predict(X_train)\n",
    "    acc_train = accuracy_score(y_train, y_train_pred) * 100\n",
    "    \n",
    "    cm_train = pd.crosstab(\n",
    "        y_train, \n",
    "        y_train_pred,\n",
    "        rownames=['Real'],\n",
    "        colnames=['Predicci√≥n']\n",
    "    )\n",
    "    sns.heatmap(cm_train, annot=True, fmt='g', ax=ax1, cmap='Blues')\n",
    "    ax1.set_title(f'{nombre_modelo} - Entrenamiento\\nAccuracy: {acc_train:.2f}%')\n",
    "    \n",
    "    # Evaluaci√≥n en prueba\n",
    "    y_test_pred = modelo.predict(X_test)\n",
    "    acc_test = accuracy_score(y_test, y_test_pred) * 100\n",
    "    \n",
    "    cm_test = pd.crosstab(\n",
    "        y_test,\n",
    "        y_test_pred,\n",
    "        rownames=['Real'],\n",
    "        colnames=['Predicci√≥n']\n",
    "    )\n",
    "    sns.heatmap(cm_test, annot=True, fmt='g', ax=ax2, cmap='Blues')\n",
    "    ax2.set_title(f'{nombre_modelo} - Prueba\\nAccuracy: {acc_test:.2f}%')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Reporte de clasificaci√≥n\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Reporte de Clasificaci√≥n - {nombre_modelo} (Conjunto de Prueba)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=['No Fraude', 'Fraude']))\n",
    "    \n",
    "    return acc_train, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matriz_confusion_con_umbral(modelo, X_test, y_test, umbral=0.5):\n",
    "    \"\"\"\n",
    "    Crea matriz de confusi√≥n usando un umbral personalizado.\n",
    "    \"\"\"\n",
    "    y_pred_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_pred_proba > umbral).astype(int)\n",
    "    \n",
    "    cm = pd.crosstab(\n",
    "        y_test,\n",
    "        y_pred,\n",
    "        rownames=['Real'],\n",
    "        colnames=['Predicci√≥n']\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues')\n",
    "    plt.title(f'Matriz de Confusi√≥n (umbral={umbral})')\n",
    "    plt.show()\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred) * 100\n",
    "    print(f\"\\nAccuracy con umbral {umbral}: {acc:.2f}%\")\n",
    "    print(f\"\\nReporte de Clasificaci√≥n:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['No Fraude', 'Fraude']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Lectura y Exploraci√≥n Inicial de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/andrestrevino/Bourbaki/Working_Analyst/Examen_reto1_clasificador_canastas_fraude/Datos/FraudeCanastas.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3666590840.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cargar datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/andrestrevino/Bourbaki/Working_Analyst/Examen_reto1_clasificador_canastas_fraude/Datos/FraudeCanastas.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dimensiones del dataset: {df.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nPrimeras filas:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/andrestrevino/Bourbaki/Working_Analyst/Examen_reto1_clasificador_canastas_fraude/Datos/FraudeCanastas.csv'"
     ]
    }
   ],
   "source": [
    "# Cargar datos\n",
    "df = pd.read_csv('/Users/andrestrevino/Bourbaki/Working_Analyst/Examen_reto1_clasificador_canastas_fraude/Datos/FraudeCanastas.csv')\n",
    "\n",
    "print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "print(f\"\\nPrimeras filas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n general\n",
    "print(\"Informaci√≥n del dataset:\")\n",
    "print(f\"Total de registros: {len(df)}\")\n",
    "print(f\"Total de columnas: {df.shape[1]}\")\n",
    "print(f\"\\nValores nulos por columna:\")\n",
    "print(df.isnull().sum().sum())  # Total de nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de la variable objetivo\n",
    "print(\"Distribuci√≥n de la variable objetivo (fraud_flag):\")\n",
    "print(df['fraud_flag'].value_counts())\n",
    "print(f\"\\nProporci√≥n:\")\n",
    "print(df['fraud_flag'].value_counts(normalize=True))\n",
    "\n",
    "# Visualizar distribuci√≥n de clases\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Conteo\n",
    "df['fraud_flag'].value_counts().plot(kind='bar', ax=ax[0], color=['green', 'red'])\n",
    "ax[0].set_title('Distribuci√≥n de Clases')\n",
    "ax[0].set_xlabel('Fraude (0=No, 1=S√≠)')\n",
    "ax[0].set_ylabel('Frecuencia')\n",
    "ax[0].set_xticklabels(['No Fraude', 'Fraude'], rotation=0)\n",
    "\n",
    "# Proporci√≥n\n",
    "df['fraud_flag'].value_counts(normalize=True).plot(kind='pie', ax=ax[1], \n",
    "                                                    autopct='%1.1f%%',\n",
    "                                                    colors=['green', 'red'],\n",
    "                                                    labels=['No Fraude', 'Fraude'])\n",
    "ax[1].set_title('Proporci√≥n de Clases')\n",
    "ax[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Dataset DESBALANCEADO: {df['fraud_flag'].value_counts(normalize=True)[0]*100:.1f}% No Fraude vs {df['fraud_flag'].value_counts(normalize=True)[1]*100:.1f}% Fraude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar las columnas de caracter√≠sticas agregadas\n",
    "caracteristicas_agregadas = ['Nb_of_items', 'total_of_items', 'costo_total', \n",
    "                              'costo_medio_item', 'costo_item_max', 'costo_item_min']\n",
    "\n",
    "print(\"Caracter√≠sticas agregadas:\")\n",
    "df[caracteristicas_agregadas].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas de productos (todas excepto ID, caracter√≠sticas agregadas y fraud_flag)\n",
    "columnas_productos = [col for col in df.columns \n",
    "                      if col not in ['ID'] + caracteristicas_agregadas + ['fraud_flag']]\n",
    "\n",
    "print(f\"Total de columnas de productos: {len(columnas_productos)}\")\n",
    "print(f\"\\nPrimeros 10 productos:\")\n",
    "print(columnas_productos[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar sparsity de los datos de productos\n",
    "productos_df = df[columnas_productos]\n",
    "total_valores = productos_df.size\n",
    "valores_cero = (productos_df == 0).sum().sum()\n",
    "sparsity = (valores_cero / total_valores) * 100\n",
    "\n",
    "print(f\"An√°lisis de Dispersi√≥n (Sparsity):\")\n",
    "print(f\"Total de valores: {total_valores:,}\")\n",
    "print(f\"Valores en cero: {valores_cero:,}\")\n",
    "print(f\"Sparsity: {sparsity:.2f}%\")\n",
    "print(f\"\\nüí° Los datos son muy dispersos (sparse), similar al problema de Bag-of-Words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Divisi√≥n Train/Test (TEMPRANA - Prevenir Data Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar caracter√≠sticas (X) y etiqueta (y)\n",
    "X = df.drop(['ID', 'fraud_flag'], axis=1)\n",
    "y = df['fraud_flag']\n",
    "\n",
    "# Divisi√≥n estratificada para mantener proporci√≥n de clases\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,\n",
    "    shuffle=True,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de Entrenamiento:\")\n",
    "print(f\"  X_train: {X_train.shape}\")\n",
    "print(f\"  y_train: {y_train.shape}\")\n",
    "print(f\"  Proporci√≥n de fraude: {y_train.mean():.3f}\")\n",
    "\n",
    "print(f\"\\nConjunto de Prueba:\")\n",
    "print(f\"  X_test: {X_test.shape}\")\n",
    "print(f\"  y_test: {y_test.shape}\")\n",
    "print(f\"  Proporci√≥n de fraude: {y_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploraci√≥n de Datos en Conjunto de Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame temporal con train data para exploraci√≥n\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# An√°lisis univariado de caracter√≠sticas agregadas por clase\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(caracteristicas_agregadas):\n",
    "    df_train.groupby('fraud_flag')[col].hist(alpha=0.6, bins=30, ax=axes[i], density=True)\n",
    "    axes[i].set_title(f'{col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].legend(['No Fraude', 'Fraude'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots de caracter√≠sticas agregadas por clase\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(caracteristicas_agregadas):\n",
    "    sns.boxplot(x='fraud_flag', y=col, data=df_train, ax=axes[i], palette='Set2')\n",
    "    axes[i].set_title(f'{col} por clase')\n",
    "    axes[i].set_xticklabels(['No Fraude', 'Fraude'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas por clase\n",
    "print(\"Estad√≠sticas de caracter√≠sticas agregadas por clase:\\n\")\n",
    "print(\"NO FRAUDE (0):\")\n",
    "print(df_train[df_train['fraud_flag']==0][caracteristicas_agregadas].describe())\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"FRAUDE (1):\")\n",
    "print(df_train[df_train['fraud_flag']==1][caracteristicas_agregadas].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n de caracter√≠sticas agregadas\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlacion = df_train[caracteristicas_agregadas + ['fraud_flag']].corr()\n",
    "sns.heatmap(correlacion, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlaci√≥n - Caracter√≠sticas Agregadas y Fraude')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelaci√≥n con fraud_flag:\")\n",
    "print(correlacion['fraud_flag'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Productos m√°s frecuentes en fraude vs no-fraude\n",
    "productos_fraude = df_train[df_train['fraud_flag']==1][columnas_productos]\n",
    "productos_no_fraude = df_train[df_train['fraud_flag']==0][columnas_productos]\n",
    "\n",
    "# Top 10 productos en canastas fraudulentas\n",
    "top_fraude = (productos_fraude > 0).sum().sort_values(ascending=False).head(10)\n",
    "print(\"Top 10 productos m√°s frecuentes en FRAUDE:\")\n",
    "print(top_fraude)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Top 10 productos en canastas no fraudulentas\n",
    "top_no_fraude = (productos_no_fraude > 0).sum().sort_values(ascending=False).head(10)\n",
    "print(\"Top 10 productos m√°s frecuentes en NO FRAUDE:\")\n",
    "print(top_no_fraude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modelo 1: Regresi√≥n Log√≠stica con Regularizaci√≥n Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Modelo Base sin Regularizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar modelo base\n",
    "modelo_base = LogisticRegression(\n",
    "    penalty=None,\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    solver='saga'\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "acc_train_base, acc_test_base = evaluacion_modelo(\n",
    "    modelo_base, X_train, y_train, X_test, y_test, \n",
    "    nombre_modelo='Regresi√≥n Log√≠stica (Sin Regularizaci√≥n)'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Grid Search para encontrar mejor C (Ridge - L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Valores de lambda y C (C = 1/lambda)\n",
    "lambdas = np.array([0.001, 0.01, 0.1, 1, 10, 100])\n",
    "C_values = 1 / lambdas\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Grid Search\n",
    "modelo_ridge = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=modelo_ridge,\n",
    "    param_grid={'C': C_values},\n",
    "    cv=kf,\n",
    "    scoring='accuracy',\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Mejor par√°metro C: {grid_search.best_params_['C']}\")\n",
    "print(f\"Mejor score (CV): {grid_search.best_score_:.4f}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados del Grid Search\n",
    "cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "cv_results_display = cv_results[['param_C', 'mean_train_score', 'mean_test_score']]\n",
    "print(\"Resultados de Grid Search:\")\n",
    "print(cv_results_display)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_train_score'], marker='o', label='Train Score')\n",
    "plt.plot(cv_results['param_C'], cv_results['mean_test_score'], marker='s', label='CV Score')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('C (1/lambda)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Grid Search: Accuracy vs C')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Entrenar modelo final con mejor C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor C\n",
    "best_C = grid_search.best_params_['C']\n",
    "\n",
    "# Entrenar modelo final\n",
    "modelo_ridge_final = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    C=best_C,\n",
    "    max_iter=1000,\n",
    "    solver='saga',\n",
    "    random_state=42\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "acc_train_ridge, acc_test_ridge = evaluacion_modelo(\n",
    "    modelo_ridge_final, X_train, y_train, X_test, y_test,\n",
    "    nombre_modelo=f'Regresi√≥n Log√≠stica Ridge (C={best_C})'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Curva ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva ROC\n",
    "RocCurveDisplay.from_estimator(modelo_ridge_final, X_test, y_test)\n",
    "plt.title('Curva ROC - Regresi√≥n Log√≠stica Ridge')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Ajuste de Umbral para Clases Desbalanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar probabilidades predichas\n",
    "y_pred_proba = modelo_ridge_final.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# DataFrame con probabilidades\n",
    "resultados = pd.DataFrame({\n",
    "    'P(Fraude)': y_pred_proba,\n",
    "    'y_real': y_test.values,\n",
    "    'y_pred_05': (y_pred_proba > 0.5).astype(int)\n",
    "})\n",
    "\n",
    "# Distribuci√≥n de probabilidades\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "resultados[resultados['y_real']==0]['P(Fraude)'].hist(bins=50, alpha=0.6, label='No Fraude', color='green')\n",
    "resultados[resultados['y_real']==1]['P(Fraude)'].hist(bins=50, alpha=0.6, label='Fraude', color='red')\n",
    "plt.xlabel('P(Fraude)')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribuci√≥n de Probabilidades Predichas')\n",
    "plt.legend()\n",
    "plt.axvline(0.5, color='black', linestyle='--', label='Umbral=0.5')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "resultados.sort_values('P(Fraude)', ascending=False).head(100)['P(Fraude)'].plot()\n",
    "plt.xlabel('Top 100 canastas')\n",
    "plt.ylabel('P(Fraude)')\n",
    "plt.title('Top 100 Probabilidades m√°s altas')\n",
    "plt.axhline(0.5, color='black', linestyle='--')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Estad√≠sticas de P(Fraude) por clase real:\")\n",
    "print(resultados.groupby('y_real')['P(Fraude)'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Probar diferentes umbrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbral = 0.3 (m√°s sensible al fraude)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"UMBRAL = 0.3\")\n",
    "print(\"=\"*60)\n",
    "matriz_confusion_con_umbral(modelo_ridge_final, X_test, y_test, umbral=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umbral = 0.2 (a√∫n m√°s sensible)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"UMBRAL = 0.2\")\n",
    "print(\"=\"*60)\n",
    "matriz_confusion_con_umbral(modelo_ridge_final, X_test, y_test, umbral=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de trade-offs con diferentes umbrales\n",
    "umbrales = np.arange(0.1, 0.9, 0.05)\n",
    "metricas = []\n",
    "\n",
    "for umbral in umbrales:\n",
    "    y_pred = (y_pred_proba > umbral).astype(int)\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    \n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    metricas.append({\n",
    "        'umbral': umbral,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "\n",
    "metricas_df = pd.DataFrame(metricas)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(metricas_df['umbral'], metricas_df['accuracy'], marker='o', label='Accuracy')\n",
    "plt.plot(metricas_df['umbral'], metricas_df['precision'], marker='s', label='Precision')\n",
    "plt.plot(metricas_df['umbral'], metricas_df['recall'], marker='^', label='Recall')\n",
    "plt.plot(metricas_df['umbral'], metricas_df['f1'], marker='d', label='F1-Score')\n",
    "plt.xlabel('Umbral')\n",
    "plt.ylabel('Score')\n",
    "plt.title('M√©tricas vs Umbral de Decisi√≥n')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.axvline(0.5, color='red', linestyle='--', alpha=0.5, label='Umbral default')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 umbrales por F1-Score:\")\n",
    "print(metricas_df.sort_values('f1', ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. An√°lisis de Coeficientes e Importancia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener coeficientes\n",
    "coeficientes = pd.Series(\n",
    "    modelo_ridge_final.coef_[0],\n",
    "    index=X_train.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 caracter√≠sticas que M√ÅS predicen FRAUDE (coeficientes positivos):\")\n",
    "print(coeficientes.head(20))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Top 20 caracter√≠sticas que M√ÅS predicen NO FRAUDE (coeficientes negativos):\")\n",
    "print(coeficientes.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar top 15 coeficientes positivos y negativos\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Top indicadores de fraude\n",
    "coeficientes.head(15).sort_values().plot(kind='barh', ax=ax1, color='red')\n",
    "ax1.set_title('Top 15 Indicadores de FRAUDE\\n(Coeficientes positivos m√°s altos)')\n",
    "ax1.set_xlabel('Coeficiente')\n",
    "ax1.axvline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# Top indicadores de no-fraude\n",
    "coeficientes.tail(15).sort_values().plot(kind='barh', ax=ax2, color='green')\n",
    "ax2.set_title('Top 15 Indicadores de NO FRAUDE\\n(Coeficientes negativos m√°s bajos)')\n",
    "ax2.set_xlabel('Coeficiente')\n",
    "ax2.axvline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lisis de caracter√≠sticas agregadas\n",
    "coefs_agregadas = coeficientes[caracteristicas_agregadas].sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "coefs_agregadas.plot(kind='barh', color=['red' if x > 0 else 'green' for x in coefs_agregadas])\n",
    "plt.title('Coeficientes de Caracter√≠sticas Agregadas')\n",
    "plt.xlabel('Coeficiente')\n",
    "plt.axvline(0, color='black', linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Coeficientes de caracter√≠sticas agregadas:\")\n",
    "print(coefs_agregadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odds Ratio (e^coeficiente)\n",
    "# Indica cu√°ntas veces aumenta/disminuye la probabilidad de fraude\n",
    "odds_ratios = np.exp(coeficientes).sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 10 Odds Ratios (productos que M√ÅS aumentan prob. de fraude):\")\n",
    "print(odds_ratios.head(10))\n",
    "print(\"\\nInterpretaci√≥n: Odds Ratio > 1 aumenta prob. de fraude\")\n",
    "print(\"               Odds Ratio < 1 disminuye prob. de fraude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Modelo 2 (Opcional): Random Forest para Comparaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Entrenar Random Forest\n",
    "modelo_rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight='balanced'  # Para manejar desbalanceo\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(\"Modelo Random Forest entrenado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar Random Forest\n",
    "acc_train_rf, acc_test_rf = evaluacion_modelo(\n",
    "    modelo_rf, X_train, y_train, X_test, y_test,\n",
    "    nombre_modelo='Random Forest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance de Random Forest\n",
    "importances = pd.Series(\n",
    "    modelo_rf.feature_importances_,\n",
    "    index=X_train.columns\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"Top 20 Features m√°s importantes (Random Forest):\")\n",
    "print(importances.head(20))\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 8))\n",
    "importances.head(20).sort_values().plot(kind='barh', color='steelblue')\n",
    "plt.title('Top 20 Features - Random Forest')\n",
    "plt.xlabel('Importancia')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar curvas ROC\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Regresi√≥n Log√≠stica Ridge\n",
    "RocCurveDisplay.from_estimator(\n",
    "    modelo_ridge_final, X_test, y_test, \n",
    "    name=f'Logistic Regression Ridge (C={best_C})',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "RocCurveDisplay.from_estimator(\n",
    "    modelo_rf, X_test, y_test,\n",
    "    name='Random Forest',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Baseline\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
    "\n",
    "ax.set_title('Comparaci√≥n de Curvas ROC')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla comparativa\n",
    "comparacion = pd.DataFrame({\n",
    "    'Modelo': ['Logistic Regression (sin reg)', 'Logistic Regression Ridge', 'Random Forest'],\n",
    "    'Accuracy Train': [acc_train_base, acc_train_ridge, acc_train_rf],\n",
    "    'Accuracy Test': [acc_test_base, acc_test_ridge, acc_test_rf]\n",
    "})\n",
    "\n",
    "print(\"\\nComparaci√≥n de Modelos:\")\n",
    "print(comparacion)\n",
    "\n",
    "# Graficar comparaci√≥n\n",
    "comparacion.set_index('Modelo')[['Accuracy Train', 'Accuracy Test']].plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Comparaci√≥n de Accuracy: Train vs Test')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Conclusiones y Recomendaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen de Resultados:\n",
    "\n",
    "### Dataset:\n",
    "- **9,318 canastas** de compra\n",
    "- **Clases desbalanceadas**: 86% No Fraude, 14% Fraude\n",
    "- **Alta dimensionalidad**: 2,474 productos (datos muy dispersos/sparse)\n",
    "- **6 caracter√≠sticas agregadas** num√©ricas\n",
    "\n",
    "### Modelos Evaluados:\n",
    "1. **Regresi√≥n Log√≠stica sin regularizaci√≥n**\n",
    "2. **Regresi√≥n Log√≠stica con Ridge (L2)** ‚Üê Modelo recomendado\n",
    "3. **Random Forest** (comparaci√≥n)\n",
    "\n",
    "### Mejor Modelo:\n",
    "**Regresi√≥n Log√≠stica con Ridge** demostr√≥ ser el modelo m√°s apropiado porque:\n",
    "- Excelente desempe√±o con datos sparse de alta dimensionalidad\n",
    "- Coeficientes interpretables\n",
    "- R√°pido entrenamiento\n",
    "- Puede ajustar umbral para optimizar detecci√≥n de fraude\n",
    "\n",
    "### Patrones de Fraude Descubiertos:\n",
    "- Ver secci√≥n 7 para productos espec√≠ficos que indican fraude\n",
    "- Caracter√≠sticas agregadas importantes: [analizar coeficientes]\n",
    "\n",
    "### Recomendaciones:\n",
    "1. **Ajustar umbral de decisi√≥n** seg√∫n costo de falsos negativos (no detectar fraude)\n",
    "2. **Monitorear productos con coeficientes positivos altos** (fuerte indicador de fraude)\n",
    "3. **Considerar caracter√≠sticas adicionales** si est√°n disponibles (hora de compra, ubicaci√≥n, etc.)\n",
    "4. **Re-entrenar modelo peri√≥dicamente** con nuevos datos para capturar patrones emergentes\n",
    "\n",
    "### M√©tricas Clave:\n",
    "- Umbral √≥ptimo: [depende del an√°lisis en secci√≥n 6]\n",
    "- Recall (captura de fraudes): [ver matriz de confusi√≥n]\n",
    "- Precision (minimizar falsos positivos): [ver matriz de confusi√≥n]\n",
    "- AUC-ROC: [ver curva ROC]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
